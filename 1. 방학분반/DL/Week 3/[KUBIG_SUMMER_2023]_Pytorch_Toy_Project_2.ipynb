{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Toy Project 2\n",
        "\n",
        "How to make CUSTOM Dataset (by imjjun KUBIG 16th)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "It is important to make the Network with some unique layers but handling with Dataset is also very important to utilize pre-organized models. We could use those models on some contests or projects.\n",
        "\n",
        "In this notebook, we might learn the pytorch's Dataset & DataLoader and handle some datasets to participate previous contests.\n"
      ],
      "metadata": {
        "id": "lfGQbwWwMmWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataModule\n",
        "\n",
        "\n",
        "*This notebook is based on the official tutorial of pytorch docs.\n",
        "\n",
        "Our goal is to make the 'Dataset iterator' to let the model fed. Pytorch fundametally offers the DataModule Class so that we could make our customized dataset for our us, which are ***Dataset***(loading the file) & ***DataLoader***(make it iterate)\n",
        "\n",
        "This notebook contains the simple & image-related exmaple. Therefore, we would make another Customized Dataset for NLP(Natural Language Process)!"
      ],
      "metadata": {
        "id": "gjfxmviUPTPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's load the ordinary Dataset: FashionMNIST\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\", #경로\n",
        "    train=True,  #train=True: 학습용 데이터 / train=False: 추론용 데이터\n",
        "    download=True, #다운로드=True, 이미 다운로드 받았으면 False로 설정 가능\n",
        "    transform=ToTensor() #transform: 이미지 변환(주로 Tensor화 혹은 Normalization 수행)\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "G0D6pDfVfy0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(training_data))\n",
        "print(type(test_data))"
      ],
      "metadata": {
        "id": "w8XLklEMgZlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can access the data as list!\n",
        "\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx] #If you access the dataset as list, the two stuffs are returned, Data & Label\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\") #squeeze: delete the dimension which is one-dimensional\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cIPogNpyginA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset\n",
        "\n",
        "*Prerequisites: Inheritance of OOP(Object-oriented Programming)\n",
        "\n",
        "*Please refer to this article if you wanna know more: https://compmath.korea.ac.kr/oop/Inheritance.html\n",
        "\n",
        "In Dataset Class, there are three modules, \\__init__(), \\__len__() and \\__getitem()__. This class is inherited by the class: torch.utils.data.Dataset.\n",
        "\n",
        "- \\__init__(): literally initialize the Class. We will load the data on the Class by defining some methods here.\n",
        "\n",
        "- \\__len__(): literally return the length of data. This is necessary to calculate the batch index, etc\n",
        "\n",
        "- \\__getitem__(): literally return the data which are needed for model. For example, image with label, or sentence with label, real image with targeted image etc"
      ],
      "metadata": {
        "id": "bHWPWOZvdBOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUMi1LpJMkAo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "\n",
        "#For FashionMNIST Data, images are stored in the 'img_dir' & labels are stored in 'annotations_file.csv'\n",
        "#csv filename extension is commonly loaded, using the python library 'pandas'\n",
        "#By using the embedded method: 'read_image' which is similar to opencv's 'imread'\n",
        "\n",
        "\n",
        "class CustomImageDataset(Dataset): #Inheritance!!\n",
        "\n",
        "    #intialize our dataset and make inputs self.object\n",
        "\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label']) #read annotation file\n",
        "        self.img_dir = img_dir #image directory\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):  #always self in Class\n",
        "        return len(self.img_labels) #return length #Usually return the label's length, since it's simpler\n",
        "\n",
        "    def __getitem__(self, idx): #we have to contain the variable\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DataLoader\n"
      ],
      "metadata": {
        "id": "qkc5XdBBbt8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fortunately, pytorch provides Basic dataloader module, \"DataLoader\"!\n",
        "\n",
        "If we define our dataset as pytorch's Dataset Class, then we can wrap up that dataset simply. Just use DataLoader Module from torch.utils.data. We can iterate that module by method **'iter()'** but the dataloader is actually not frequently used directly.\n",
        "\n",
        "There are some variables which you have to choose:\n",
        "\n",
        "- **Batch Size**: You have to choose your batch size, considering your domain, hardware etc. Usually, the bigger batch size, the better performance.\n",
        "\n",
        "- **shuffle**: Usually True on Train Dataset & False on Test Dataset\n",
        "\n",
        "- **pin_memory**: Simply speaking, data is allocated directly to VRAM, not to DRAM (Dram is what we usually call RAM & VRAM is RAM of GPU)\n",
        "\n",
        "- **num_workers**: the number of subprocss of data multi processing [ Usually set to 4 * (the # of GPU) ]"
      ],
      "metadata": {
        "id": "tecuXXnBbCP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "a_bi1VFybv2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_dataloader))\n",
        "print(type(test_dataloader))"
      ],
      "metadata": {
        "id": "sgHHtxqjd0Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "wRCZsw7Bd5go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Link\n",
        "\n",
        "\n",
        "\n",
        "https://dacon.io/competitions/official/235747/overview/description\n",
        "\n",
        "We will participate this competition on the next month :)\n"
      ],
      "metadata": {
        "id": "777r4EPVTY1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Download the Dataset"
      ],
      "metadata": {
        "id": "wsqNhteLeaoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1pg-Q42ybABcXaoInyF-QRqdr8tRx3A-R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX0GSmJQTNrJ",
        "outputId": "8aa84191-af2a-49a3-dbdd-8abae9faed7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pg-Q42ybABcXaoInyF-QRqdr8tRx3A-R\n",
            "To: /content/open.zip\n",
            "\r  0% 0.00/1.91M [00:00<?, ?B/s]\r 55% 1.05M/1.91M [00:00<00:00, 9.12MB/s]\r100% 1.91M/1.91M [00:00<00:00, 14.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/open.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJZvN5zHhzaJ",
        "outputId": "4bec1e54-4373-4e9e-f656-4ca0fedc217d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/open.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_data.csv           \n",
            "  inflating: topic_dict.csv          \n",
            "  inflating: train_data.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Install the one of NLP packages, Transformer"
      ],
      "metadata": {
        "id": "oBAWrVAkedn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "mJDmklIXeX06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416cfeca-8cf2-45e4-cb08-57b7179b4fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/7.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/7.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/7.4 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer #This AutoTokenizer would be useful to make word embeddings\n",
        "import torch\n",
        "\n",
        "#tokenizer=AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "#y=tokenizer(text, return_tensors='pt',truncation=True, max_length=20, pad_to_max_length=True, add_special_token=True)\n",
        "\n",
        "#https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer <- You can refer to it\n",
        "\n",
        "#Access like 'config'\n",
        "\n",
        "#input_id=y['input_ids']\n",
        "\n",
        "#attention_mask=y['attention_mask']\n",
        "\n",
        "\"\"\"Inputs:\n",
        "    - text -> sentence\n",
        "    - return_tensor -> 'pt': pytorch, 'np': numpy etc\n",
        "    - truncation -> Allow sentence truncation(문장 잘림)\n",
        "    - max length -> Word embeddings' maximal length for dimensionality\n",
        "    - pad to max length -> Match the length with the longest sentence\n",
        "    - add_special_token -> Add special tokens related to pretrained model(BERT, RoBERTa etc)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"Outputs:\n",
        "    - input_ids -> Table of Tokenized inputs\n",
        "    - attention_mask -> Seperating between token and padded token\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OfLlDpCweZ0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) How does the dataset look like?\n",
        "\n",
        "\n",
        "Output: You have to show the csv file by any methods(pandas, numpy etc). Plz print it out on this ipynb."
      ],
      "metadata": {
        "id": "eoqjeSkBe2OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plz print out the dataset by any methods\n"
      ],
      "metadata": {
        "id": "Cq72OJJWe19P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6d62bb6c-ee1a-49d6-d65e-c9ef6734c121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                             title  topic_idx\n",
              "0      0          인천→핀란드 항공기 결항…휴가철 여행객 분통          4\n",
              "1      1    실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화          4\n",
              "2      2    이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것          4\n",
              "3      3  NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합          4\n",
              "4      4         시진핑 트럼프에 중미 무역협상 조속 타결 희망          4"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-45f1fb76-ebdb-4a07-ab6a-361d647e71af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f1fb76-ebdb-4a07-ab6a-361d647e71af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0e46d84c-28a7-4749-b230-b72eb7100af9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e46d84c-28a7-4749-b230-b72eb7100af9')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0e46d84c-28a7-4749-b230-b72eb7100af9 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45f1fb76-ebdb-4a07-ab6a-361d647e71af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45f1fb76-ebdb-4a07-ab6a-361d647e71af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Make your Dataset!\n",
        "\n",
        "Make only **'train set'**, not test set"
      ],
      "metadata": {
        "id": "Ovl6tFvWfcVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define your function or code to utilize the given dataset as pytorch Dataset !\n",
        "# You can refer to the code sharing tap of above dacon homepage :)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class NLPDataset_train(Dataset):\n",
        "\n",
        "    \"\"\" Dataset Implementation\n",
        "        You have to implement them on __init__,\n",
        "        and return your embeddings through __getitem__ (Outputs might be returned through this method).\n",
        "        Don't forget the __len__!\n",
        "\n",
        "        Inputs:\n",
        "        - csv file which contains ['topic','classification index']\n",
        "        - AutoTokenizer of Transformer for word embeddings -> Vectorization of Sentences\n",
        "\n",
        "        Outputs:\n",
        "        - input_ids:idx of given sentence\n",
        "        - attention_mask: Simply, word embeddings\n",
        "        - label: the category of given sentence\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, csv):\n",
        "\n",
        "\n",
        "      return None\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "      return None\n",
        "\n",
        "\n",
        "    def __getitem__(self):\n",
        "\n",
        "      return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IZBtH3erVxpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) See what components are iterated!"
      ],
      "metadata": {
        "id": "g8oiAgS-BipP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading your dataset\n",
        "train_loader = DataLoader(NLPDataset_train, batch_size=16, shuffle=True)\n",
        "input_iter, mask_iter, label_iter = iter(train_dataloader)\n",
        "\n",
        "#Print out train batch !\n",
        "print(f\"Feature batch: {next(input_iter), next(mask_iter)}\")\n",
        "print(f\"Feature batch size: {next(input_iter.shape, next(mask_iter.shape))}\")\n",
        "print(f\"Labels batch & size: {next(label_iter), next(label_iter.shape)}\")"
      ],
      "metadata": {
        "id": "9K_Ojyhhfhva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}