{"cells":[{"cell_type":"markdown","source":["#3주차 과제 설명\n","<p>이번 과제의 목표는 세션 시간에 개념으로 배운 Visualization을 직접 실습해보면서 CNN안에서는 무슨 일이 일어나는지, Gradient ascent가 실제로 어떻게 작동하는 것인지 여러분들이 몸소 느끼시는 것입니다.</p>\n","\n","<p>평소에 하셨던 어떤 모델 구현이나, 학습을 시키는 과정은 아니지만 딥러닝에게 매번 주어지는 근본적인 과제인 \"도대체 얘네는 무엇을, 어떻게 하고 있는 것이냐\"에 대한 자그마한 체험이시라고 생각하시면 될 것 같습니다 😂</p>\n","\n","<p> 주어진 과제는 총 3개이며 훌륭한 교보재인 CS231 공식 assignment 3을 대다수 참고하였습니다 🙇🏻‍♂️</p>"],"metadata":{"id":"Gv1pJdQ7MYKu"}},{"cell_type":"markdown","source":["# Drive Mount & Download COCO"],"metadata":{"id":"2yolex4ENuq7"}},{"cell_type":"code","source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"JZsvCiL8VSbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCNCEFN99DNF"},"outputs":[],"source":["# 본인의 다운로드받은 폴더경로에 맞게 설정해주시면 됩니다.\n","FOLDERNAME = \"/2023_summer_kubig\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# COCO dataset을 다운받을 수 있게 해줍니다\n","# if it doesn't already exist.\n","%cd /content/drive/My\\ Drive/$FOLDERNAME\n","!bash get_imagenet_val.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"markdown","metadata":{"collapsed":true,"tags":["pdf-title"],"id":"APaGwyY29DNX"},"source":["# Network Visualization\n","\n","\n","\n","*   Image gradients (Gradient ascent)를 활용해 새로운 이미지를 생성해봅니다\n","*   Pretrained된 모델을 사용하고, loss function을 목적에 맞게 지정하여 이미지 픽셀과 loss간의 gradient를 backpropagation을 통해 계산합니다\n","\n","*   모델의 가중치는 고정하고, loss를 줄이는 방향으로 새로운 이미지를 합성하기 위해 Gradient descent on the image (Gradient ascent)를 적용합니다\n","\n","<br>\n","\n","<h1>Image Generation을 위한 3가지 technique을 학습합니다</h1>\n","\n","\n","1.   Saliency Maps : 어떤 이미지 픽셀이 classification decision에 영향을 주는가?\n","2.   Fooling images: pretrained network를 교란시킬 수 있는 image를 만들어보자\n","3. Class Visualization : 특정 클래스의 classification score를 최대화할 수 있는 이미지를 합성해보자"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pdf-ignore"],"id":"7YDFZ9g_9DNf"},"outputs":[],"source":["# Setup cell.\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import os\n","from scipy.ndimage import gaussian_filter1d\n","from PIL import Image\n","\n","SQUEEZENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n","SQUEEZENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # Set default size of plots.\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","source":["## Help Function"],"metadata":{"id":"ZzBXmGCKKxau"}},{"cell_type":"markdown","source":["\n","\n","<b>사용할 Pretrained model이 이미 표준화된 이미지에 대해 학습돼서, 과제의 편의를 위해 Model inference에 필요한 전처리 관련 함수들을 미리 모아놓았습니다.</b>\n","\n"],"metadata":{"id":"ZrQqot9XP-JP"}},{"cell_type":"code","source":["def preprocess(img, size=224): #Standard-scaling\n","    transform = T.Compose([\n","        T.Resize(size),\n","        T.ToTensor(),\n","        T.Normalize(mean=SQUEEZENET_MEAN.tolist(),\n","                    std=SQUEEZENET_STD.tolist()),\n","        T.Lambda(lambda x: x[None]),\n","    ])\n","    return transform(img)\n","\n","def deprocess(img, should_rescale=True):\n","    transform = T.Compose([\n","        T.Lambda(lambda x: x[0]),\n","        T.Normalize(mean=[0, 0, 0], std=(1.0 / SQUEEZENET_STD).tolist()),\n","        T.Normalize(mean=(-SQUEEZENET_MEAN).tolist(), std=[1, 1, 1]),\n","        T.Lambda(rescale) if should_rescale else T.Lambda(lambda x: x),\n","        T.ToPILImage(),\n","    ])\n","    return transform(img)\n","\n","def rescale(x): #Minmax-scaling\n","    low, high = x.min(), x.max()\n","    x_rescaled = (x - low) / (high - low)\n","    return x_rescaled\n","\n","def blur_image(X, sigma=1): #Gaussian_filter\n","    X_np = X.cpu().clone().numpy()\n","    X_np = gaussian_filter1d(X_np, sigma, axis=2)\n","    X_np = gaussian_filter1d(X_np, sigma, axis=3)\n","    X.copy_(torch.Tensor(X_np).type_as(X))\n","    return X\n","\n","def jitter(X, ox, oy): #pixel change\n","    \"\"\"\n","    Helper function to randomly jitter an image.\n","\n","    Inputs\n","    - X: PyTorch Tensor of shape (N, C, H, W)\n","    - ox, oy: Integers giving number of pixels to jitter along W and H axes\n","\n","    Returns: A new PyTorch Tensor of shape (N, C, H, W)\n","    \"\"\"\n","    if ox != 0:\n","        left = X[:, :, :, :-ox]\n","        right = X[:, :, :, -ox:]\n","        X = torch.cat([right, left], dim=3)\n","    if oy != 0:\n","        top = X[:, :, :-oy]\n","        bottom = X[:, :, -oy:]\n","        X = torch.cat([bottom, top], dim=2)\n","    return X\n"],"metadata":{"id":"oR4TvAXq4sOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Imagenet_valid 데이터를 불러오기 위한 함수입니다 <br>\n","밑에 다운로드 받을 파일 경로만 수정해주시면 됩니다!"],"metadata":{"id":"G97IbCCE8KNl"}},{"cell_type":"code","source":["def load_imagenet_val(num=None):\n","    \"\"\"Load a handful of validation images from ImageNet.\n","\n","    Inputs:\n","    - num: Number of images to load (max of 25)\n","\n","    Returns:\n","    - X: numpy array with shape [num, 224, 224, 3]\n","    - y: numpy array of integer image labels, shape [num]\n","    - class_names: dict mapping integer label to class name\n","    \"\"\"\n","    imagenet_fn = os.path.join(\"imagenet_val_25.npz\")\n","    if not os.path.isfile(imagenet_fn):\n","        print(\"file %s not found\" % imagenet_fn)\n","        print(\"Run the following:\")\n","        print(\"\")\n","        print(\"bash get_imagenet_val.sh\")\n","        assert False, \"Need to download imagenet_val_25.npz\"\n","\n","    # modify the default parameters of np.load\n","    # https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa\n","    np_load_old = np.load\n","    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n","    f = np.load(imagenet_fn)\n","    np.load = np_load_old\n","    X = f[\"X\"]\n","    y = f[\"y\"]\n","    class_names = f[\"label_map\"].item()\n","    if num is not None:\n","        X = X[:num]\n","        y = y[:num]\n","    return X, y, class_names"],"metadata":{"id":"7B8StQok8JPm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6SS57rU89DNm"},"source":["# Pretrained Model\n","\n","## Image Generation 항목에서는 ImageNet에서 pretrained한 model을 사용합니다.\n","\n","\n","*   특히 여기서는 Squeezenet이라는 모델을 사용하는데 AlexNet과 유사하지만 훨씬 더 가볍고 빠른 모델입니다\n","*   CPU로도 Image Generation이 가능합니다\n","\n","\n","[1] Iandola et al, \"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and < 0.5MB model size\", arXiv 2016"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znVNVJDx9DNo"},"outputs":[],"source":["# Download and load the pretrained SqueezeNet model.\n","model = torchvision.models.squeezenet1_1(pretrained=True)\n","\n","# Gradient 계산 X\n","for param in model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"ngQ6H9W59DNq"},"source":["## Loading ImageNet Validation Images\n","\n","\n","*   ImageNet의 validation set image sample들을 살펴봅시다\n","*   Valid set이므로 Pretrained model이 학습하지 않은 것"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pdf-ignore"],"id":"IRuEfjXv9DNt"},"outputs":[],"source":["X, y, class_names = load_imagenet_val(num=5)\n","\n","plt.figure(figsize=(12, 6))\n","for i in range(5):\n","    plt.subplot(1, 5, i + 1)\n","    plt.imshow(X[i])\n","    plt.title(class_names[y[i]])\n","    plt.axis('off')\n","plt.gcf().tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"7ebdpAPV9DNu"},"source":["# Saliency Maps : 어떤 이미지 픽셀이 classification decision에 영향을 주는가?\n","\n","\n","\n","\n","1.  정답 클래스에 해당하는 unnormalized score의 gradient를 이미지의 픽셀에 대해 계산합니다.\n","2.  Image Shape : (3,H,W) -> Gradient Shape : (3,H,W)\n","3.  각 픽셀에 대하여, gradient는 픽셀값이 바뀔때마다 classification score가 얼만큼 변할지를 의미\n","4. Gradient의 절댓값 계산 -> 3 channel에 대한 maximum value만 (H,W) saliency map에 보존 (모든 값들은 음수가 아닙니다.)\n","\n","[2] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. \"Deep Inside Convolutional Networks: Visualising\n","Image Classification Models and Saliency Maps\", ICLR Workshop 2014."]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"0tZAS1yp9DNw"},"source":["### Hint: PyTorch `gather` method\n","\n","*   `s` = PyTorch Tensor of shape `(N, C)` : 2d array\n","*   `y` = PyTorch Tensor of shape `(N,)` : 1d array containing longs in the range `0 <= y[i] < C`\n","\n","그러면,\n","\n","`s.gather(1, y.view(-1, 1)).squeeze()`\n","\n","*   `s.gather(1, y.view(-1, 1)).squeeze()` : 기존 `(N, C)` 2차원 배열에서 y의 인덱스에 따라 행별로 하나의 원소만을 선택한 `(N,)` 1차원 배열이 된다\n","*   `s.gather(dim: index하고 싶은 축, index: index에 필요한 원소)`\n","\n","\n","*   `s.squeeze()` : size가 1인 차원 축소\n","\n","\n","https://pytorch.org/docs/stable/generated/torch.squeeze<br>\n","https://pytorch.org/docs/stable/generated/torch.gather"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pdf-ignore"],"id":"b4s5AFdm9DNz"},"outputs":[],"source":["# Example of using gather to select one entry from each row in PyTorch\n","def gather_example():\n","    N, C = 4, 5\n","    s = torch.randn(N, C)\n","    y = torch.LongTensor([1, 2, 1, 3])\n","    print(s)\n","    print(y)\n","    print(s.gather(1, y.view(-1, 1)).squeeze())\n","gather_example()"]},{"cell_type":"markdown","metadata":{"id":"22HHkhYW9DN0"},"source":["#과제 1 : Compute Salinecy Maps 함수 짜기"]},{"cell_type":"markdown","source":["* *Saliency Map: 이미지 데이터 픽셀 중 어떤 픽셀이 classification에 큰 영향을 주는지*\n","* *그 중 SOD 방식: 이미지 내에서 사람이 중요하다고 생각할 물체/지역을 검출*"],"metadata":{"id":"TRKbp9qbn1Dv"}},{"cell_type":"code","source":["def compute_saliency_maps(X, y, model):\n","    \"\"\"\n","    Compute a class saliency map using the model for images X and labels y.\n","\n","    Input:\n","    - X: Input images; Tensor of shape (N, 3, H, W)\n","    - y: Labels for X; LongTensor of shape (N,)\n","    - model: A pretrained CNN\n","\n","    Returns:\n","    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n","    images.\n","    \"\"\"\n","    # Make sure the model is in \"test\" mode\n","\n","    model.eval()\n","\n","    # Make input tensor require gradient\n","\n","    X.requires_grad_()\n","\n","    saliency = None\n","\n","    ##############################################################################\n","    # TODO: 굳이 scratch로 구현안하셔도 되고 pytorch 라이브러리 쓰시면 됩니다.\n","\n","    # 빈칸 작성 3가지\n","    # 1. Forward pass 구현 : compute the loss over the correct class score\n","    # 2. Backward pass 구현 : compute gradient of the correct class score\n","    # 3. saliency 구현\n","    ##############################################################################\n","    #1.Forward pass : softmax를 쓰지 않습니다 -> unnormalize score\n","    #Hint: Loss를 계산하려면 기본적으로 모델의 예측값과 Label값을 이용해야겟죠?\n","    #추가적으로 Batch내 element loss를 다 합쳐서 loss를 결합해주세요\n","\n","    scores = model(X)\n","\n","    loss = torch.sum(scores.gather(1,y.view(-1,1)).squeeze())\n","\n","    #2.backward pass\n","\n","    loss.backward()\n","\n","    #3.우리가 원하는 saliency는 입력 이미지 각각에 관한 class score gradient\n","    #그래디언트에 절댓값을 씌우고, channel에 대해 max value값을 취해주세요\n","\n","    saliency = X.grad.abs()\n","\n","    saliency,_ = torch.max(saliency,1)\n","\n","    ##############################################################################\n","    #                             END OF YOUR CODE                               #\n","    ##############################################################################\n","\n","    return saliency"],"metadata":{"id":"loUCD2pEZGm9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위에서 구현한 함수를 바탕으로 saliency_map을 visualization해보세요"],"metadata":{"id":"Bt6fUpug8hy6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7q_yt7U9DN5"},"outputs":[],"source":["def show_saliency_maps(X, y):\n","    # Convert X and y from numpy arrays to Torch Tensors\n","    X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n","    y_tensor = torch.LongTensor(y)\n","\n","    # 정답 클래스에 대해서만 saliency_map을 적용\n","    saliency = compute_saliency_maps(X_tensor, y_tensor, model)\n","\n","    # Convert the saliency map from Torch Tensor to numpy array and show images\n","    # and saliency maps together.\n","    saliency = saliency.numpy()\n","    N = X.shape[0]\n","    for i in range(N):\n","        plt.subplot(2, N, i + 1)\n","        plt.imshow(X[i])\n","        plt.axis('off')\n","        plt.title(class_names[y[i]])\n","        plt.subplot(2, N, N + i + 1)\n","        plt.imshow(saliency[i], cmap=plt.cm.hot)\n","        plt.axis('off')\n","        plt.gcf().set_size_inches(12, 5)\n","    plt.show()\n","\n","show_saliency_maps(X, y)"]},{"cell_type":"markdown","metadata":{"id":"E6iecIy_9DN7"},"source":["# Fooling Images : pretrained network를 교란시킬 수 있는 image를 만들어보자\n","\n","1.   Image와 target class가 주어졌을때, target class의 classification score를 최대화하는 방향으로 gradient ascent를 사용해 image를 update할 수 있습니다\n","2.   Network가 실제로 이미지를 target class로 분류하면 update를 중지합니다\n","\n","[3] Szegedy et al, \"Intriguing properties of neural networks\", ICLR 2014\n","\n","Implement ```make_fooling_image``` function inside ```cs231n/net_visualization_pytorch.py```"]},{"cell_type":"markdown","source":["* *fooling images: 실제 정답 class가 아닌 다른 target class를 설정한 후, 해당 이미지가 target class로 분류될 때까지 반복.*"],"metadata":{"id":"iQdIv24UoBl1"}},{"cell_type":"markdown","source":["#과제 2 : make_fooling_image 함수 짜기"],"metadata":{"id":"pnBiMhTrxUL3"}},{"cell_type":"code","source":["def make_fooling_image(X, target_y, model):\n","    \"\"\"\n","    Generate a fooling image that is close to X, but that the model classifies\n","    as target_y.\n","\n","    Inputs:\n","    - X: Input image; Tensor of shape (1, 3, 224, 224)\n","    - target_y: An integer in the range [0, 1000)\n","    - model: A pretrained CNN\n","\n","    Returns:\n","    - X_fooling: An image that is close to X, but that is classifed as target_y\n","    by the model.\n","    \"\"\"\n","    # 네트워크를 속일 가짜 이미지를 만듭니다.\n","    X_fooling = X.clone()\n","    X_fooling = X_fooling.requires_grad_()\n","\n","    learning_rate = 1\n","\n","    ##############################################################################\n","    # TODO:\n","    # 1.반복문을 작성하여 target class score에 대한 gradient ascent를 사용해 X_fooling을 update합니다\n","    # 2.Network가 X_fooling을 target_y로 분류할때까지 반복합니다\n","\n","\n","    #빈칸 작성 5가지, 아래의 #######부분을 채워주세요\n","    ##############################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    while True:\n","\n","        #1. 모델의 output을 얻으세요\n","\n","        pred_y = model(X_fooling)\n","\n","        #2. 모델의 output이 target class이라면?\n","\n","        index = torch.argmax(pred_y, dim=1)\n","\n","        if index[0] == target_y:\n","          break\n","\n","        #3. 여기서의 Loss는 무엇일까요? 우리가 무엇을 하기 위해 fooling image를 만들었나요?\n","\n","        loss = pred_y[0, target_y]\n","\n","        #4. Backpropagation\n","\n","        loss.backward()\n","\n","        grad = X_fooling.grad.data\n","\n","        #5.Gradient ascent를 통해 image update를 진행합니다.\n","        #Image update를 하고나서는 반드시 이것을 해줘야합니다. 그래야 반복해서 그래디언트를 계산하겟죠?\n","        #Hint: dX = learning_rate * g / ||g||_2. (L2 norm을 적용한 normliazed graient step을 사용합니다)\n","\n","        X_fooling.data += learning_rate * (grad / grad.norm())\n","\n","        X_fooling.grad.zero_()\n","\n","    ##############################################################################\n","    #                             END OF YOUR CODE                               #\n","    ##############################################################################\n","    return X_fooling"],"metadata":{"id":"vDJkBuyBLSSY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWiWI45B9DN9"},"outputs":[],"source":["idx = 0\n","target_y = 6\n","\n","X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n","X_fooling = make_fooling_image(X_tensor[idx:idx+1], target_y, model)\n","\n","scores = model(X_fooling)\n","assert target_y == scores.data.max(1)[1][0].item(), 'The model is not fooled!'"]},{"cell_type":"markdown","metadata":{"id":"nyt3QIXB9DN-"},"source":["Fooling image를 만들어보고 original image와 비교해보세요!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0uHcVua9DN_"},"outputs":[],"source":["X_fooling_np = deprocess(X_fooling.clone())\n","X_fooling_np = np.asarray(X_fooling_np).astype(np.uint8)\n","\n","plt.subplot(1, 4, 1)\n","plt.imshow(X[idx])\n","plt.title(class_names[y[idx]])\n","plt.axis('off')\n","\n","plt.subplot(1, 4, 2)\n","plt.imshow(X_fooling_np)\n","plt.title(class_names[target_y])\n","plt.axis('off')\n","\n","plt.subplot(1, 4, 3)\n","X_pre = preprocess(Image.fromarray(X[idx]))\n","diff = np.asarray(deprocess(X_fooling - X_pre, should_rescale=False))\n","plt.imshow(diff)\n","plt.title('Difference')\n","plt.axis('off')\n","\n","plt.subplot(1, 4, 4)\n","diff = np.asarray(deprocess(10 * (X_fooling - X_pre), should_rescale=False))\n","plt.imshow(diff)\n","plt.title('Magnified difference (10x)')\n","plt.axis('off')\n","\n","plt.gcf().set_size_inches(12, 5)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"SGie01E39DOA"},"source":["# Class Visualization : 특정 클래스의 classification score를 최대화할 수 있는 이미지를 합성해보자\n","\n","\n","1. Class Visualization은 랜덤 노이즈 이미지를 시작으로 target class에 대해 gradient ascent를 수행하여, network가 target class로 인식하는 이미지를 생성하는 기법입니다.\n","2. Several Regularization technique과 함께 쓰여 generated image를 자연스럽게 보이도록 합니다.\n","3. $s_y(I)$ : CNN이 image $I$를 class $y$라고 classification하는 score (before softmax)\n","4. $R$ : L2 Regularizer\n","$$\n","I^* = \\arg\\max_I (s_y(I) - R(I))\n","$$\n","\n","$$\n","R(I) = \\lambda \\|I\\|_2^2\n","$$\n","\n","5. 위의 Optimization problem을 gradient ascent로 해결하는 것\n","\n","\n","[2] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. \"Deep Inside Convolutional Networks: Visualising\n","Image Classification Models and Saliency Maps\", ICLR Workshop 2014.\n","\n","[3] Yosinski et al, \"Understanding Neural Networks Through Deep Visualization\", ICML 2015 Deep Learning Workshop"]},{"cell_type":"markdown","source":["#과제 3 : class_visualization_update_step 함수 짜기"],"metadata":{"id":"i7NKt5dc5n2u"}},{"cell_type":"code","source":["def make_fooling_image(X, target_y, model):\n","\n","    # 네트워크를 속일 가짜 이미지를 만듭니다.\n","    X_fooling = X.clone()\n","    X_fooling = X_fooling.requires_grad_()\n","\n","    learning_rate = 1\n","\n","    while True:\n","        #1. 모델의 output을 얻으세요\n","\n","        pred_y = model(X_fooling)\n","\n","        #2. 모델의 output이 target class이라면?\n","\n","        index = torch.argmax(pred_y, dim=1)\n","\n","        if index[0] == target_y:\n","          break\n","\n","        #3. 여기서의 Loss는 무엇일까요? 우리가 무엇을 하기 위해 fooling image를 만들었나요?\n","\n","        loss = pred_y[0, target_y]\n","\n","        #4. Backpropagation\n","\n","        loss.backward()\n","\n","        grad = X_fooling.grad.data\n","\n","        #5.Gradient ascent를 통해 image update를 진행합니다.\n","        #Image update를 하고나서는 반드시 이것을 해줘야합니다. 그래야 반복해서 그래디언트를 계산하겟죠?\n","        #Hint: dX = learning_rate * g / ||g||_2. (L2 norm을 적용한 normliazed graient step을 사용합니다)\n","\n","        X_fooling.data += learning_rate * (grad / grad.norm())\n","\n","        X_fooling.grad.zero_()\n","\n","    return X_fooling"],"metadata":{"id":"MCSN8IEnuJGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def class_visualization_update_step(img, model, target_y, l2_reg, learning_rate):\n","    ########################################################################\n","    #TODO:\n","    #1.target_y class score에 대한 image 픽셀의 gradient 계산\n","    #2.Gradient ascent 수행 with regularization\n","\n","\n","    #과제 2와 과정이 거의 유사하므로 위의 2가지를 수행할 수 있는 코드를 자유롭게 작성해주세요\n","    #Regularization이 들어가므로 부호에 주의하세요!\n","    ########################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","    pred_y = model(img)\n","\n","    loss = pred_y[:, target_y]- (l2_reg * torch.square(torch.norm(img)))\n","\n","    loss.backward()\n","\n","    img.data += learning_rate * img.grad.data\n","\n","    img.grad.data.zero_()\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ########################################################################\n","    #                             END OF YOUR CODE                         #\n","    ########################################################################"],"metadata":{"id":"1Bgy1tv02IWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4QrLbvB9DOB"},"outputs":[],"source":["def create_class_visualization(target_y, model, dtype, **kwargs):\n","    \"\"\"\n","    Generate an image to maximize the score of target_y under a pretrained model.\n","\n","    Inputs:\n","    - target_y: Integer in the range [0, 1000) giving the index of the class\n","    - model: A pretrained CNN that will be used to generate the image\n","    - dtype: Torch datatype to use for computations\n","\n","    Keyword arguments:\n","    - l2_reg: Strength of L2 regularization on the image\n","    - learning_rate: How big of a step to take\n","    - num_iterations: How many iterations to use\n","    - blur_every: How often to blur the image as an implicit regularizer\n","    - max_jitter: How much to gjitter the image as an implicit regularizer\n","    - show_every: How often to show the intermediate result\n","    \"\"\"\n","    model.type(dtype)\n","    l2_reg = kwargs.pop('l2_reg', 1e-3)\n","    learning_rate = kwargs.pop('learning_rate', 25)\n","    num_iterations = kwargs.pop('num_iterations', 100)\n","    blur_every = kwargs.pop('blur_every', 10)\n","    max_jitter = kwargs.pop('max_jitter', 16)\n","    show_every = kwargs.pop('show_every', 25)\n","\n","    # Randomly initialize the image as a PyTorch Tensor, and make it requires gradient.\n","    img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype).requires_grad_()\n","\n","    for t in range(num_iterations):\n","        # Randomly jitter the image a bit; this gives slightly nicer results\n","        ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter)\n","        img.data.copy_(jitter(img.data, ox, oy))\n","        class_visualization_update_step(img, model, target_y, l2_reg, learning_rate)\n","        # Undo the random jitter\n","        img.data.copy_(jitter(img.data, -ox, -oy))\n","\n","        # As regularizer, clamp and periodically blur the image\n","        for c in range(3):\n","            lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c])\n","            hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c])\n","            img.data[:, c].clamp_(min=lo, max=hi)\n","        if t % blur_every == 0:\n","            blur_image(img.data, sigma=0.5)\n","\n","        # Periodically show the image\n","        if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:\n","            plt.imshow(deprocess(img.data.clone().cpu()))\n","            class_name = class_names[target_y]\n","            plt.title('%s\\nIteration %d / %d' % (class_name, t + 1, num_iterations))\n","            plt.gcf().set_size_inches(4, 4)\n","            plt.axis('off')\n","            plt.show()\n","\n","    return deprocess(img.data.cpu())"]},{"cell_type":"markdown","source":["실제 원하는 target class의 이미지가 만들어지는 과정을 살펴보세요"],"metadata":{"id":"TAgB6sLo5Un2"}},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"r1y60fQ39DOC"},"outputs":[],"source":["dtype = torch.FloatTensor\n","model.type(dtype)\n","\n","target_y = 76 # Tarantula\n","# target_y = 78 # Tick\n","# target_y = 187 # Yorkshire Terrier\n","# target_y = 683 # Oboe\n","# target_y = 366 # Gorilla\n","# target_y = 604 # Hourglass\n","out = create_class_visualization(target_y, model, dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7_Q9r7i9DOE"},"outputs":[],"source":["# target_y = 78 # Tick\n","# target_y = 187 # Yorkshire Terrier\n","# target_y = 683 # Oboe\n","# target_y = 366 # Gorilla\n","# target_y = 604 # Hourglass\n","\n","target_y = np.random.randint(1000)\n","print(class_names[target_y])\n","X = create_class_visualization(target_y, model, dtype)"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}